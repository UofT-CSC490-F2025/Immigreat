transformers
datasets
evaluate
scikit-learn
pandas
numpy
trl                         # HuggingFace TRL (for PPO/DPO)
accelerate                  # For trainer acceleration
peft                        # For parameter-efficient fine-tuning (optional)
openai                      # If using GPT-4 or GPT-3.5 as judge
sentence-transformers       # For embedding-based similarity
nltk                        # For token-based metrics (BLEU, ROUGE)
seaborn
ipykernel
jupyter
python-dotenv
peft>=0.5.0
bitsandbytes>=0.41.0
sentencepiece  # for some LLMs (like T5)
accelerate  # for multi-GPU or model dispatching
datasets>=2.14.0
transformers>=4.36.0
accelerate>=0.25.0
bitsandbytes>=0.41.0
peft>=0.7.0
trl>=0.7.0
datasets>=2.16.0
wandb>=0.16.0
tensorboard>=2.15.0
numpy>=1.24.0
tqdm>=4.66.0
scipy>=1.11.0
